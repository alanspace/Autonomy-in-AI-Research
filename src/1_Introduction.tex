\section{Introduction}
Artificial intelligence (AI) and robotics have evolved extraordinarily since their mid-20th century emergence. Initially grounded in symbolic reasoning and basic automation, these fields are now complex, multifaceted disciplines integral to modern society. AI systems, no longer confined to digital infrastructures like recommendation algorithms, are increasingly embodied via advancements in robotics. Particularly striking is the recent advent of human-like robots powered by sophisticated large language models (LLMs). These entities convincingly simulate nuanced human behaviors, producing coherent, contextually aware, and seemingly meaningful responses. This convergence of advanced AI with realistic humanoid forms, moving from research labs into industries like customer service and entertainment, has re-ignited profound philosophical and ethical questions echoing early AI debates.

Alan Turing’s 1950 paper, "Computing Machinery and Intelligence," is a cornerstone in this discourse \citep{Turing1950}. His challenge—“Can machines think?”—and the Turing Test offered a pragmatic, though still debated, approach to machine intelligence, sidestepping abstract definitions of "thinking." While Turing's question has resonated for decades, this paper builds upon that legacy, shifting focus to arguably more intricate inquiries: Can machines be conscious? Do they possess subjective experience? Can they act with philosophically meaningful autonomy? These questions compel examination beyond AI's external behaviors, urging deeper interrogation of the concepts—consciousness, subjectivity, and autonomy—defining human experience and agency.

This paper argues that while current AI, including LLM-powered humanoids, achieves remarkable simulations of these human-centric attributes, a critical distinction remains between sophisticated mimicry and genuine, self-derived instances of these phenomena. Our primary aim is not to definitively answer whether AI \emph{will} achieve such states, but to critically investigate the applicability of these terms to non-biological systems. Exploring philosophical, technical, and ethical perspectives, we interrogate conceptual boundaries: Can these phenomena emerge in artificial substrates, or are they inextricably tied to biological, embodied cognition? Ultimately, this exploration seeks a more precise, interdisciplinary dialogue about intelligence, experience, and agency where artificial-organic lines blur, concluding with a proposed stance on the nature and limitations of autonomy in contemporary AI.
