# Autonomy in AI: Exploring Subjectivity in Humanoid AI
Authors: Shek Lun Leung, Alexander Näslund
Institution: KTH Royal Institute of Technology

## Overview
This repository contains the research paper "Autonomy in AI - (Can Machines Be Conscious?)", which investigates the "simulation-reality gap" in advanced LLM-powered humanoid robots.

## Key Contributions & Safety Implications
- The Simulation-Reality Gap: We argue that behavioral mimicry in contemporary AI does not equate to philosophical autonomy.
- AI Welfare & Accountability: We evaluate the ethical risks of delegating human accountability to systems that convincingly simulate sentience.
- Relevance to AI Safety: This work aligns with Anthropic’s research tracks on AI Welfare and Scalable Oversight, advocating for a precautionary approach to the deployment of autonomous agents.

## How to Cite
@article{LeungNaslund2025,
  title={Autonomy in AI: Exploring Subjectivity in Humanoid AI},
  author={Leung, Shek Lun and N{\"a}slund, Alexander},
  year={2025},
  institution={KTH Royal Institute of Technology}
}